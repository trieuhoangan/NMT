# -*- coding: utf-8 -*-
"""tree2seq model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uvVaMTdjT4DsjvNYrm00TTgiaZbPIctv
"""

# !git clone https://github.com/VinAIResearch/PhoNLP

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive

# Commented out IPython magic to ensure Python compatibility.
# %cd PhoNLP/

# Commented out IPython magic to ensure Python compatibility.
# %ls

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

"""Prepare Dataset """

import torch
import torch.nn as nn
import torch.nn.functional as F
import re
import torch.cuda as tc
import numpy as np
from torch import optim
import math

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device = torch.device('cuda:0')
input_size = 100
hidden_size = 100
p_dropout = 0.01
max_length = 202

import matplotlib.pyplot as plt
plt.switch_backend('agg')
import matplotlib.ticker as ticker

def showPlot(points):
    plt.figure()
    fig, ax = plt.subplots()
    # this locator puts ticks at regular intervals
    loc = ticker.MultipleLocator(base=0.2)
    ax.yaxis.set_major_locator(loc)
    plt.plot(points)

!pip3 install -e .



import phonlp
dir = './models/dependency_parsing_models/pretrained_phonlp'
# phonlp.download(save_dir=dir)
parsing_model = phonlp.load(save_dir=dir)
# model.print_out(model.annotate(text="Xin đọc về bút hiệu Nguyễn Ái Quốc tại Nguyễn Ái Quốc (bút hiệu) .")

# token_list = parsing_model.annotate(output_type='conll',text="Nổ trong không khí hay cháy hoàn toàn diễn ra chậm hơn 15,000 lần so với những phản ứng trong động cơ xe")
# parsing_model.print_out(token_list)

# token_list[0][0]

class PhoNode:
  def __init__(self,text='',pos='',ner='',id=-1,level=-1,dependency_relation=''):
    self.text = text
    self.pos = pos
    self.ner = ner
    self.id = id
    self.level = level
    self.dependency_relation = dependency_relation
    self.childList = []
    self.father = None
    self.isLeaf = False
    self.part = []
    self.left = None
    self.right = None
    self.h = None
    self.c = None
    self.word_index = 0
  def setRight(self,listnode):
    self.right = listnode

  def setLeft(self, listnode):
    self.left = listnode

  def setPart(self,parts):
    self.part = parts

  def getLevel(self):
    return self.level

  def getID(self):
    return self.id

  def addChild(self,node):
    self.childList.append(node)
    
  def addFather(self,node):
    self.father = node

  def levelDown(self):
    self.level = self.level +1
    for child in self.childList:
      child.levelDown()

  def printChildList(self):
    if len(self.childList)>0:
      print('node number {}'.format(self.id))
      for child in self.childList:
        child.print_out()
      for child in self.childList:
        child.printChildList()
    else:
      print("node {} is a leaf at level {}".format(self.id,self.level))

  def simplifiedNode(self):
    if len(self.childList) >2:
      return 0
    return -1

  def checkLeaf(self):
    if len(self.childList) ==0:
      self.isLeaf = True
    else:
      self.isLeaf = False

  def print_out_bin_tree(self):
    text = ''
    if len(self.part) != 0:
      for node in self.part:
        text = text + ' ' + node.text
    
    print('{}'.format(text))
    # if self.left!=None:
    #   self.left.print_out_bin_tree()
    # if self.right!=None:
    #   self.right.print_out_bin_tree()
    # left_text = ''
    # right_text = ''
    # if self.left != None:
    #   for node in self.left.part:
    #     left_text = left_text +' '+node.text
    # if self.right!=None:
    #   for node in self.right.part:
    #     right_text = right_text + ' ' + node.text
    # print('main: {} |  left : {}  | right : {}'.format(text,left_text,right_text))
    if self.left!=None:
      self.left.print_out_bin_tree()
    if self.right!=None:
      self.right.print_out_bin_tree()

  def clear_bin_tree(self):
    self.clear_part_context()
    if self.left!=None:
      self.left.clear_bin_tree()
    if self.right!=None:
      self.right.clear_bin_tree()

  def clear_part_context(self):
    if len(self.part) > 1:
      self.part = []

  def convert_bin_tree_to_word_index(self,model):
    if len(self.part)!=0:
      if self.part[0].text in model.vocab:
        self.part[0].word_index = model.vocab[self.part[0].text].index
      else:
        self.part[0].word_index = -1
    if self.left!=None:
      self.left.convert_bin_tree_to_word_index(model)
    if self.right!=None:
      self.right.convert_bin_tree_to_word_index(model)

  def print_word_indices(self):
    if len(self.part) !=0:
      print('index',self.part[0].word_index)
    if self.left!=None:
      self.left.print_word_indices()
    if self.right!=None:
      self.right.print_word_indices()

  def print_out(self):
    print("id: {}, text: {} , pos: {} , ner : {}, level: {} , dependency_relation: {}".format(self.id,self.text,self.pos,self.ner,self.level,self.dependency_relation))

class Tree_:

  def __init__(self,token_list):
    self.nodeList = self.make_node_list(token_list)
    self.root = PhoNode('','','',-1,'-1','')
    self.root = self.getRoot()
    self.numNode = len(token_list[0][0])
    # self.create_connection()

  def make_node_list(self,token_list):
    num_token = len(token_list[0][0])
    nodeList = []
    for i in range(num_token):
      id = i
      text = token_list[0][0][i]
      pos = token_list[1][0][i][0]
      ner = token_list[2][0][i]
      level = token_list[3][0][i][0]
      dependency_relation = token_list[3][0][i][1]
      node = PhoNode(text,pos,ner,id,int(level),dependency_relation)
      # node.print_out()
      nodeList.append(node)
    return nodeList

  def getRoot(self):
    node_ = None
    for node in self.nodeList:
      if node.getLevel()==0:
        node_ = node
        return node_
    return PhoNode('','','',-1,-1,'')

  def create_connection(self):
    max_level = self.get_max_level()
    self.nodeList = self.sort_as_level()
    levelList = self.create_level_list(self.nodeList)
    numLevel = len(levelList)
    for i in range(numLevel):
      if i ==0:
        continue
      else:
        nodeNum = len(levelList[i])
        for j in range(nodeNum):
          mindist,father = self.cal_node_dist(levelList[i-1],levelList[i][j])
          father.addChild(levelList[i][j])
          levelList[i][j].addFather(father)

  def get_min_level_token(self,nodelist):
    min_level = 1000
    next_root = -1
    for node in nodelist:
      if node.level < min_level:
        min_level = node.level
        next_root = node.id
    return next_root,min_level

  def make_binary_tree(self,parts):
    root = PhoNode()
    root.setPart(parts)
    if len(parts) == 1:
      return root
    if len(parts) == 2:
      # print('got 2 word alone')
      # parts[0].print_out()
      # parts[1].print_out()
      leftNode = PhoNode()
      rightNode = PhoNode()
      leftNode.setPart([parts[0]])
      rightNode.setPart([parts[1]])
      root.setLeft(leftNode)
      root.setRight(rightNode)
      leftNode.father = root
      rightNode.father = root
      return root
    id_min,min_lv = self.get_min_level_token(parts)
    left_part = []
    right_part = []
    center_node = None
    for node in parts:
      if node.id < id_min:
        left_part.append(node)
      elif node.id > id_min:
        right_part.append(node)
      elif node.id == id_min and center_node == None:
        center_node = node
      else:
        right_part.append(node)
    if len(left_part)!=0 and len(right_part)!=0:
      left_part.append(center_node)
      right = self.make_binary_tree(right_part)
      right.father = root
      root.setRight(right)
      left = self.make_binary_tree(left_part)
      left.father = root
      root.setLeft(left)
    elif len(left_part) == 0:
      center = PhoNode()
      center.setPart([center_node])
      root.setLeft(center)
      center.father = root
      right = self.make_binary_tree(right_part)
      right.father = root
      root.setRight(right)
    elif len(right_part)== 0:
      center = PhoNode()
      center.setPart([center_node])
      root.setRight(center)
      center.father = root
      left = self.make_binary_tree(left_part)
      left.father = root
      root.setLeft(left)
    return root

  def cal_node_dist(self,nodeList,childnode):
    min_dist = 10000
    father = childnode
    for node in nodeList:
      dist = node.id - childnode.id
      if dist <0:
        dist = dist*-1
      if dist < min_dist:
        min_dist = dist
        father = node
    return min_dist,father

  def create_level_list(self,sortedList):
    current_level = 0
    levelList = []
    currentLevel = []
    for node in sortedList:
      if node.level == current_level:
        currentLevel.append(node)
      else:
        current_level = node.level
        levelList.append(currentLevel)
        currentLevel=[]
        currentLevel.append(node)
    # for level in levelList:
    #   level[0].print_out()
    return levelList

  def sort_as_level(self):
    listNode = self.nodeList
    numNode = self.numNode
    for i in range(0,numNode):
      for j in range(i+1,numNode):
        if listNode[i].level > listNode[j].level:
          tmpNode = listNode[j]
          listNode[j] = listNode[i]
          listNode[i] = tmpNode
    # for node in listNode:
    #   node.print_out()
    return listNode
  
  def get_max_level(self):
    max_level = 0
    for node in self.nodeList:
      if node.level > max_level:
        max_level = node.level
    return max_level

  def print_out(self):
    for node in self.nodeList:
      node.print_out()

# tree = Tree_(token_list)
# # tree.print_out()
# # tree.getRoot().print_out()
# # tree.sort_as_level()
# # tree.create_connection()
# # tree.root.printChildList()
# bin_tree = tree.make_binary_tree(tree.nodeList)
# bin_tree.clear_bin_tree()
# # bin_tree.convert_bin_tree_to_word_index()
# # bin_tree.print_out_bin_tree()

# preprocessing data
def preprocessing(sentence):
  sentence = re.sub(r"&apos",r" ",sentence)
  sentence = re.sub(r"&quot;",r" ",sentence)
  sentence = re.sub(r";s",r"s",sentence)
  sentence = re.sub(r"([?.!,¿])", r" \1 ", sentence)
  sentence = re.sub(r'[" "]', " ", sentence)
  sentence = re.sub(r'[","]', "", sentence)
  sentence = re.sub(r'&#93', "", sentence)
  sentence = re.sub(r'&#91', "", sentence)
  sentence.strip()
  # sentence = '<start> '+sentence+' <end>'
  return sentence
def preprocess_batch(sentences):
  real_sent = []
  for sentence in sentences:
    sentence = preprocessing(sentence)
    sentence = '<start> '+sentence+' <end>'
    # real_sent.append(sentence.split(' '))
    real_sent.append(sentence)
  return real_sent
def preprocessing_without_start(sentences):
  real_sent = []
  for sentence in sentences:
    sentence = preprocessing(sentence)
    sentence = sentence+' <end>'
    # real_sent.append(sentence.split(' '))
    real_sent.append(sentence)
  return real_sent
def split_and_preprocessing_fortesting(sentences):
  real_sent = []
  for sentence in sentences:
    sentence = preprocessing(sentence)
    sentence = sentence+' <end>'
    # real_sent.append(sentence.split(' '))
    real_sent.append(sentence)
  return real_sent

# Commented out IPython magic to ensure Python compatibility.
# %ls

dev_data_en_path = '../DataForNMT/2013/dev-2012-en-vi/tst2012.en'
dev_data_vi_path = '../DataForNMT/2013/dev-2012-en-vi/tst2012.vi'
train_data_en_path = '../DataForNMT/2013/train-en-vi/train.en'
train_data_vi_path = '../DataForNMT/2013/train-en-vi/train.vi'
test_data_en_path = '../DataForNMT/2013/test-2013-en-vi/tst2013.en'
test_data_vi_path = '../DataForNMT/2013/test-2013-en-vi/tst2013.vi'

dev_text_en = open(dev_data_en_path, 'rb').read().decode(encoding='utf-8')
dev_text_vi = open(dev_data_vi_path, 'rb').read().decode(encoding='utf-8')
train_text_en = open(train_data_en_path, 'rb').read().decode(encoding='utf-8')
train_text_vi = open(train_data_vi_path, 'rb').read().decode(encoding='utf-8')
test_text_en = open(test_data_en_path, 'rb').read().decode(encoding='utf-8')
test_text_vi = open(test_data_vi_path, 'rb').read().decode(encoding='utf-8')
# print('Length of text: {} characters'.format(len(text_en)))
# print(text_en[:500])

train_vi_sentences = []
train_en_sentences = []
test_vi_sentences = []
test_en_sentences = []
dev_vi_sentences = []
dev_en_sentences = []

dev_en_sentences.extend(dev_text_en.split('\n'))
train_en_sentences.extend(train_text_en.split('\n'))
test_en_sentences.extend(test_text_en.split('\n'))

dev_vi_sentences.extend(dev_text_vi.split('\n'))
train_vi_sentences.extend(train_text_vi.split('\n'))
test_vi_sentences.extend(test_text_vi.split('\n'))

path_to_file_vi = '../models/language_models/vi_model.bin'
path_to_file_en = '../models/language_models/en_model.bin'
import gensim
en_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_file_en,binary=True)
vi_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_file_vi,binary=True)

# bin_tree.convert_bin_tree_to_word_index(vi_model)
# bin_tree.print_word_indices()

dev_en = preprocessing_without_start(dev_en_sentences)
dev_vi = preprocess_batch(dev_vi_sentences)
train_en = preprocess_batch(train_en_sentences)
train_vi = preprocess_batch(train_vi_sentences)
test_vi = preprocess_batch(test_vi_sentences)
test_en = preprocess_batch(test_en_sentences)

def indexesFromSentence(model, sentence,MAX_SEQUENCE_LENGTH):
    # actuall_indices = [model.vocab[word].index for word in sentence if word!='']
    indices = np.zeros(MAX_SEQUENCE_LENGTH)
    indices = indices+1
    pos = 0
    # length = 0
    for word in sentence.split(' '):
      if word!='':
        indices[pos] = model.vocab[word].index
        pos=pos+1
    return indices,pos
def tensorFromSentence(model, sentences,MAX_SEQUENCE_LENGTH):
  # print(len(sentences))
  indexesList = []
  lengths = []
  for sentence in sentences:
    indexes,length = indexesFromSentence(model, sentence,MAX_SEQUENCE_LENGTH)
    indexesList.append(indexes)
    lengths.append(length)
    # indexes.append(EOS_token)
  return torch.tensor(indexesList, dtype=torch.long, device=device),lengths

#prepare forest
def save_forest_to_file(sentence_batch,parsing_model,file_path,error_path):
  error_parsing = []
  add_error = open(error_path,'a',encoding='utf-8')
  with open(file_path,'a',encoding='utf-8') as f:
    for sentence in sentence_batch:
      try:
        token_list =  parsing_model.annotate(text=sentence)
      except:
        # add_error = open(error_path,'a',encoding='utf-8')
        add_error.write(sentence+'\n')
        # add_error.close()
        # error_parsing.append(sentence)
      text_form = ''
      for word in token_list[0][0]:
        text_form=text_form+word+','
      text_form= text_form+'|'
      for pos in token_list[1][0]:
        text_form = text_form + pos[0] + ','
      text_form= text_form+'|'
      for ner in token_list[2][0]:
        text_form=text_form+ner+','
      text_form= text_form+'|'
      for head_index in token_list[3][0]:
        text_form = text_form + head_index[0]+':'+head_index[1]+','
      f.write(text_form+'\n')
    return error_parsing
def load_token_list_from_file(file_path):
  lines =  open(file_path,'r',encoding='utf-8').read().split('\n')
  token_list = []
  for line in lines:
    if line =='':
      continue
    words = []
    poss = []
    ners = []
    head_indexes = []
    feature = line.split('|')
    for word in feature[0].split(','):
      if word !='':
        words.append(word)
    for pos in feature[1].split(','):
      if pos !='':
        poss.append([pos])
    for ner in feature[2].split(','):
      if ner!='':
        ners.append(ner)
    for index in feature[3].split(','):
      if index!='':
        # part = index.split(':')
        head_indexes.append(index.split(':'))
    listone = []
    listone.append([words])
    listone.append([poss])
    listone.append([ners])
    listone.append([head_indexes])
    token_list.append(listone)
  return token_list
def create_forest(list_token_list,embedding_model):
  forest = []
  for token_list in list_token_list:
    tree = Tree_(token_list)
    bin_tree = tree.make_binary_tree(tree.nodeList)
    bin_tree.clear_bin_tree()
    bin_tree.convert_bin_tree_to_word_index(vi_model)
    # bin_tree.print_word_indices()
    forest.append(bin_tree)
  return forest

def get_k_elements(source_list,batch_size,start_point):
  result = []
  for i in range(0,batch_size):
    result.append(source_list[start_point+i])
  return result
# k = get_k_elements(dev_vi,32,0)

dev_file_path = '../DataForNMT/2013/dev_phonlp_token_list.txt'
train_file_path = '../DataForNMT/2013/train_phonlp_token_list.txt'
test_file_path = '../DataForNMT/2013/test_phonlp_token_list.txt'
train_error_path = '../DataForNMT/2013/error_train_phonlp_token_list.txt'
test_error_path = '../DataForNMT/2013/error_test_phonlp_token_list.txt'
limit = 0
from  torch.nn.utils.rnn import pack_padded_sequence
# with open(train_file_path,'r',encoding='utf-8') as f:
#   lines = f.readlines()
#   # print(len(lines))
#   limit += len(lines)
# with open(train_error_path,'r',encoding='utf-8') as f:
#   lines = f.readlines()
#   # print(len(lines))
#   limit += len(lines)
# print(limit)
# save_forest_to_file(dev_vi,parsing_model,dev_file_path)
# error_train = save_forest_to_file(train_vi[limit:],parsing_model,train_file_path,train_error_path)
# error_test = save_forest_to_file(test_vi,parsing_model,test_file_path,test_error_path)
# lst = load_token_list_from_file(dev_file_path)



# forest = create_forest(lst[:64],vi_model)
# dev_vi_input,vi_lengths = tensorFromSentence(vi_model,dev_vi[:64],900)
# dev_en_input,en_lengths = tensorFromSentence(en_model,dev_en[:64],900)
# dev_vi_input = pack_padded_sequence(dev_vi_input,vi_lengths,batch_first =True,enforce_sorted = False)
# dev_en_input = pack_padded_sequence(dev_en_input,en_lengths,batch_first =True,enforce_sorted = False)
# print(len(forest))

"""Define TreeLSTM cell"""

class BinaryTreeLSTMCell(nn.Module):
  '''
    TreeLSTMCell is defined based on the format of LSTM function of torch.nn
    TreeLSTMCell receive input as a batch of tree and calculate the state of each node in the tree
  '''
  def __init__(self,input_size, hidden_size,MAX_LENGTH,embedding,p_dropout):
    super(BinaryTreeLSTMCell, self).__init__()
    self.input_size = input_size
    self.hidden_size = hidden_size
    self.dropout = nn.Dropout(p=p_dropout)
    self.embedding = embedding
    self.max_length = MAX_LENGTH
    # self.U_i_l = nn.Parameter(
    #         torch.Tensor(hidden_size, hidden_size),
    #         requires_grad=True)
    self.U_i_l = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.U_i_r = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.b_i = nn.Parameter(
            torch.ones(hidden_size, 1),
            requires_grad=True).to(device)
    self.U_fl_l = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.U_fl_r = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.b_fl = nn.Parameter(
            torch.ones(hidden_size, 1),
            requires_grad=True).to(device)
    self.U_fr_l = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.U_fr_r = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.b_fr = nn.Parameter(
            torch.ones(hidden_size, 1),
            requires_grad=True).to(device)
    self.U_o_l = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.U_o_r = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.b_o = nn.Parameter(
            torch.ones(hidden_size, 1),
            requires_grad=True).to(device)
    self.U_c_l = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.U_c_r = nn.Parameter(
            torch.ones(hidden_size, hidden_size),
            requires_grad=True).to(device)
    self.b_c = nn.Parameter(
            torch.ones(hidden_size, 1),
            requires_grad=True).to(device)
  '''
    input: root node of the tree
      return:
        output at shape (T,B,H*num_direction) ( in this case num_direction is 1 so shape is T*B*H)
        Tuble (h,c) of shape (num_layer*numdirection,B,H) in this case (1,B,H)
  '''
  def forward(self,input_forest):
    forest_output = None
    forest_h = None
    forest_c = None
    for tree in input_forest:
      tree_output,(tree_h,tree_c) = self.tree_traversal(tree)
      if tree_output == None:
        tree_output = torch.zeros(self.max_length,self.hidden_size)
        tree_h = torch.zeros(1,self.hidden_size)
        tree_c = torch.zeros(1,self.hidden_size)
      else:
        tree_output = self.widen_output(tree_output)
      if forest_output == None:
        forest_output = tree_output.unsqueeze(0)
        forest_h = tree_h.unsqueeze(0)
        forest_c = tree_c.unsqueeze(0)
      else:
        forest_output = torch.cat((forest_output,tree_output.unsqueeze(0)),dim=0)
        forest_c = torch.cat((forest_c,tree_c.unsqueeze(0)),dim=0)
        forest_h = torch.cat((forest_h,tree_h.unsqueeze(0)),dim=0)
        
    return forest_output,(forest_h.transpose(0,1),forest_c.transpose(0,1))
  '''
    param input_left and input_right: 
       left input and right input state of the decoder, in shape (H,1)
    param c_k_left and c_k_right:
        memory cell of left node and right node in shape (H,1)
    return:
        h and c of current node in shape (H,1)
    the current state and memory are calculated as
              ik  = σ (U(i)l*h_k_left + U(i)r*h_k_right + b(i)
              flk = σ (U(fl)l*h_k_left + U(fl)r*h_k_right + b(fl))
              frk = σ (U(fr)l*h_k_left + U(fr)r*h_k_right + b(fr))
              ok  = σ (U(o)l*h_k_left + U(o)r*h_k_right + b(o))
              ck = tanh(U(c)l*h_k_left + U(c)r*h_k_right + b(c))
              c(phr)k = ik

  '''
  def calculate(self,input_left,input_right,c_k_left, c_k_right):
    i = torch.sigmoid((torch.matmul(self.U_i_l,input_left) + torch.matmul(self.U_i_r,input_right) + self.b_i))
    f_k_left = torch.sigmoid((torch.matmul(self.U_fl_l,input_left) + torch.matmul(self.U_fl_r,input_right) + self.b_fl))
    f_k_right = torch.sigmoid((torch.matmul(self.U_fr_l,input_left) + torch.matmul(self.U_fr_r,input_right) + self.b_fr))
    o_k = torch.sigmoid((torch.matmul(self.U_o_l,input_left) + torch.matmul(self.U_o_r,input_right) + self.b_o))
    c_k = torch.tanh((torch.matmul(self.U_c_l,input_left) + torch.matmul(self.U_c_r,input_right) + self.b_c))
    c_k_phr = i*c_k + f_k_left*c_k_left + f_k_right*c_k_right
    h_k_phr = o_k*torch.tanh(c_k_phr)
    return h_k_phr,c_k_phr
  '''
      input : a single root node of a tree
          tree_traversal function handle 1 tree each time it is called
      return: output is at shape(T,1,H*num_directions ) in this case num_directions  = 1 <=> (T,1,H) => (T,H) to ease
      tuple(h,c) is at shape (num_layers * num_directions,1,H) <=> (1,H)
  '''
  def tree_traversal(self,node):
    tmp = node
    output = None
    hs = []
    while tmp.h == None:
      if tmp.left == None and tmp.right == None:
        
        if len(tmp.part) > 0:
          if tmp.part[0].word_index !=-1:
            h = self.embedding(torch.Tensor([tmp.part[0].word_index]).to(torch.int64).to(device))
            h = torch.transpose(h, 0, 1)
          else:
            h = torch.ones(self.hidden_size,1).to(device)- 0.5
        else:
          h = torch.ones(self.hidden_size,1).to(device) -0.5
        c_phr = torch.ones(self.hidden_size, 1).to(device) - 0.5
        tmp.h = h
        tmp.c = c_phr
        tmp = tmp.father
        continue
      if tmp.left != None:
        if tmp.left.h == None:
          tmp = tmp.left
          continue
      if tmp.right != None:
        if tmp.right.h == None:
          tmp = tmp.right
          continue
      h,c = self.calculate(tmp.left.h,tmp.right.h,tmp.left.c,tmp.right.c) # Hx1
      # print(h.shape)
      tmp.h = h
      tmp.c = c
      hs.append(h)
      if tmp.father!= None:
        tmp = tmp.father
    if len(hs) == 0:
      output = None
      print(None)
    else:
      output = hs[0].transpose(0,1)
      for i in range(len(hs)):
        output = torch.cat((output,hs[i].transpose(0,1)),dim=0)
      # print(output.shape)
    return output, (tmp.h.transpose(0,1).to(device), tmp.c.transpose(0,1).to(device))
  def widen_output(self,output):
    while output.shape[0] < self.max_length:
      output = torch.cat((output,torch.zeros(1,self.hidden_size).to(device)),dim=0)
    return output
  def get_inithidden(self):
    return torch.ones((self.hidden_size,1)).to(device)

a = torch.randn((5,1))
b = torch.randn((5,1))
c = torch.randn((5,1))
c = c.transpose(0,1).unsqueeze(0)
c.shape



path_to_file_vi = '../models/language_models/vi_model.bin'
path_to_file_en = '../models/language_models/en_model.bin'
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
def get_pre_train_model(path_to_file):
  import gensim
  model = gensim.models.KeyedVectors.load_word2vec_format(path_to_file,binary=True)
  weights = torch.FloatTensor(model.vectors).to(device)
  embedding = nn.Embedding.from_pretrained(weights)
  return embedding
embedding = get_pre_train_model(path_to_file_vi)

# left = embedding(torch.Tensor([105]).to(torch.int64)).view(1, 1, -1)
# right = embedding(torch.Tensor([3757]).to(torch.int64)).view(1, 1, -1)
# # left[0].shape
# input_left = torch.transpose(left[0], 0, 1)
# input_right = torch.transpose(right[0], 0, 1)
# # input_left = left[0]
# # input_right = right[0]

# cell = BinaryTreeLSTMCell(10,100,900,embedding,0.01)
# ckl = torch.ones(100,1)
# ckr = torch.ones(100,1) + 1
# c,h = cell.calculate(input_left,input_right,ckl,ckr)
# print("c shape: ",c.shape)
# print("h shape",h.shape)

"""Define Encoder"""

import gensim

class Tree2SeqEncoder(nn.Module):
  def __init__(self,input_size,hidden_size,max_length,p_dropout,path_to_embedding):
    super(Tree2SeqEncoder,self).__init__()
    self.input_size = input_size
    self.hidden_size = hidden_size
    self.p_dropout = p_dropout
    self.max_length = max_length
    model = gensim.models.KeyedVectors.load_word2vec_format(path_to_embedding,binary=True)
    weights = torch.FloatTensor(model.vectors).to(device)
    self.embedding = nn.Embedding.from_pretrained(weights)
    self.TreeLSTMcell = BinaryTreeLSTMCell(input_size,hidden_size,max_length,self.embedding,p_dropout)
    self.LSTM = nn.LSTM(input_size, hidden_size,batch_first =True)
    
  
  '''
    input of sequence is shape of (B,T)
    input of Tree is shape (B)
    return : 
      output of tree in shape (B,T,H) and h,c in shape (1,B,H)
      output of sequence in shape (B,T,H) and h,c in shape (1,B,H)
  '''
  def forward(self,input_sequences, input_forest):
    input_sequences = self.embedding(input_sequences)
    output, hidden_of_sequence = self.LSTM(input_sequences)
    output_of_sequence = output
    c_of_sequence = hidden_of_sequence
    # print("finished compute sequence hidden")
    output_of_tree,c_of_tree = self.TreeLSTMcell(input_forest)
 
    return output_of_tree, output_of_sequence, c_of_tree,c_of_sequence

# input_size = 100
# hidden_size = 100
# max_length = 900
# p_dropout = 0.01
# path_to_embedding = path_to_file_vi
# enc = Tree2SeqEncoder(input_size,hidden_size,max_length,p_dropout,path_to_embedding)
# h_tr,h_s,c_tr,c_s = enc(dev_vi_input,vi_lengths,forest)
# print('htr',h_tr.shape)
# print('hs',h_s.shape)
# print('c_s_h',c_s[0].shape)
# print('c_s_c',c_s[1].shape)
# print('c_tr_h',c_tr[0].shape)
# print('c_tr_c',c_tr[1].shape)

# print(h_tr.shape)

class Attn(nn.Module):
    def __init__(self, method, hidden_size):
        super(Attn, self).__init__()
        self.method = method
        self.hidden_size = hidden_size
        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)
        self.v = nn.Parameter(torch.ones(hidden_size))
        stdv = 1. / math.sqrt(self.v.size(0))
        self.v.data.normal_(mean=0, std=stdv)

    def forward(self, hidden, encoder_outputs, src_len=None):
        '''
        :param hidden: 
            previous hidden state of the decoder, in shape (layers*directions,B,H)
        :param encoder_outputs:
            encoder outputs from Encoder, in shape (T,B,H)
        :param src_len:
            used for masking. NoneType or tensor in shape (B) indicating sequence length
        :return
            attention energies in shape (B,T)
        '''
        
        max_len = encoder_outputs.size(0)
        this_batch_size = encoder_outputs.size(1)
        H = hidden.repeat(max_len,1,1).transpose(0,1)
        encoder_outputs = encoder_outputs.transpose(0,1) # [B*T*H]
        attn_energies = self.score(H,encoder_outputs) # compute attention score
        
        if src_len is not None:
            mask = []
            for b in range(src_len.size(0)):
                mask.append([0] * src_len[b].item() + [1] * (encoder_outputs.size(1) - src_len[b].item()))
            mask = cuda_(torch.ByteTensor(mask).unsqueeze(1)) # [B,1,T]
            attn_energies = attn_energies.masked_fill(mask, -1e18)
        
        return F.softmax(attn_energies).unsqueeze(1) # normalize with softmax

    def score(self, hidden, encoder_outputs):
        energy = torch.tanh(self.attn(torch.cat([hidden, encoder_outputs], 2))) # [B*T*2H]->[B*T*H]
        energy = energy.transpose(2,1) # [B*H*T]
        v = self.v.repeat(encoder_outputs.data.shape[0],1).unsqueeze(1) #[B*1*H]
        energy = torch.bmm(v,energy) # [B*1*T]
        return energy.squeeze(1) #[B*T]

def catch_error(objecive):
  print(objecive)

import gensim
class Decoder(nn.Module):
  def __init__(self,input_size,hidden_size,max_length,embedding_path,embed_size,output_size,n_layers=1,dropout_p=0.1):
    super(Decoder,self).__init__()
    self.input_size = input_size
    self.hidden_size = hidden_size
    model = gensim.models.KeyedVectors.load_word2vec_format(embedding_path,binary=True)
    weights = torch.FloatTensor(model.vectors).to(device)
    self.embedding = nn.Embedding.from_pretrained(weights).to(device)
    # Define parameters
    self.output_size = output_size
    self.n_layers = n_layers
    self.dropout_p = dropout_p
    # Define layers
    self.dropout = nn.Dropout(dropout_p)
    self.attn = Attn('concat', hidden_size)
    gru_input_size = hidden_size + embed_size
    self.gru = nn.GRU(gru_input_size, hidden_size, dropout=dropout_p)
    #self.attn_combine = nn.Linear(hidden_size + embed_size, hidden_size)
    self.out = nn.Linear(hidden_size, output_size)
    self.treeLSTM = BinaryTreeLSTMCell(input_size,hidden_size,max_length,self.embedding,dropout_p)
  def forward(self, word_input, last_hidden, encoder_outputs, tree_encoder_outputs):
    '''
    :param word_input:
        word input for current time step, in shape (B)
    :param last_hidden:
        last hidden stat of the decoder, in shape (layers*direction*B*H)
    :param encoder_outputs:
        encoder outputs in shape (T*B*H)
    :return
        decoder output
    Note: we run this one step at a time i.e. you should use a outer loop 
        to process the whole sequence
    Tip(update):
    EncoderRNN may be bidirectional or have multiple layers, so the shape of hidden states can be 
    different from that of DecoderRNN
    You may have to manually guarantee that they have the same dimension outside this function,
    e.g, select the encoder hidden state of the foward/backward pass.
    '''
    # Get the embedding of the current input word (last output word)
    
    # word_embedded = self.embedding(word_input).view(1, word_input.size(0), -1) # (1,B,V)
    try:
      word_embedded = self.embedding(word_input)
    except:
      catch_error(word_input)
    word_embedded = word_embedded.unsqueeze(0)
    word_embedded = self.dropout(word_embedded)
    # Calculate attention weights and apply to encoder outputs
    lhidden = last_hidden[-1]
    # print(lhidden.shape)
    # if index == 0:
      # lhidden,lc = self.treeLSTM()
    attn_weights = self.attn(lhidden, encoder_outputs)
    tree_attn_weights = self.attn(lhidden, tree_encoder_outputs)

    # the attention is not very correct, need to concat hidden state of tree and sequence before these. 
    context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,V)
    tree_context = tree_attn_weights.bmm(encoder_outputs.transpose(0, 1))
    context = context.transpose(0, 1)  # (1,B,V)
    tree_context = tree_context.transpose(0,1)
    context = tree_context + context


    # Combine embedded input word and attended context, run through RNN
    rnn_input = torch.cat((word_embedded, context), 2)
    # print('rrn input',rnn_input.shape)
    #rnn_input = self.attn_combine(rnn_input) # use it in case your size of rnn_input is different
    output, hidden = self.gru(rnn_input, lhidden)
    output = output.squeeze(0)  # (1,B,V)->(B,V)
    # context = context.squeeze(0)
    # update: "context" input before final layer can be problematic.
    # output = F.log_softmax(self.out(torch.cat((output, context), 1)))
    output = F.log_softmax(self.out(output))
    # Return final output, hidden state
    return output, hidden.unsqueeze(0),attn_weights,tree_attn_weights
  '''
    tree_ouput has shape (1,B,H)
    seq_output has shape (1,B,H)
    c_tree has shape (num)layer*direction,B,H)
    c_seq has shape (num)layer*direction,B,H)
    return first_hidden at shape (layers,direction,B,H)
  '''
  def get_first_hidden(self,tree_last_hidden,seq_last_hidden,c_tree,c_seq):
    first_hiddens = []
    for i in range(int(tree_last_hidden.shape[1])):
      hidden_one,c_one = self.treeLSTM.calculate(tree_last_hidden[0][i].unsqueeze(1),
                                           seq_last_hidden[0][i].unsqueeze(1),
                                           c_tree[0][i].unsqueeze(1),
                                           c_seq[0][i].unsqueeze(1)
                                           )
      if i ==0:
        first_hiddens = hidden_one
      else:
        first_hiddens = torch.cat((first_hiddens,hidden_one),dim=1)
    first_hiddens = first_hiddens.transpose(0,1)
    first_hiddens = first_hiddens.unsqueeze(0)
    first_hiddens = first_hiddens.unsqueeze(0)
    return first_hiddens

# first_hidden = dec.get_first_hidden(c_tr[0],c_s[0],c_tr[1],c_s[1])

# print(h_tr.shape)
# print(h_tr[1][9])
# first_hidden.shape

# word_input = []
# # en_model = get_pre_train_model(path_to_file_en)
# for i in range(64):
#   word_input.append(en_model.vocab['<start>'].index)
# words = torch.tensor(word_input)
# dec_output,dec_hidden,attn_weight_seq,attn_weight_tree = dec(words, first_hidden, h_s.transpose(0,1), h_tr.transpose(0,1))

# print(dec_output.shape)
# print(dec_hidden.shape)

import time
import math


def asMinutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)


def timeSince(since, percent):
    now = time.time()
    s = now - since
    es = s / (percent)
    rs = es - s
    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))

"""Define training strategy"""

path_to_file_vi = '../models/language_models/vi_model.bin'
path_to_file_en = '../models/language_models/en_model.bin'
import gensim
en_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_file_en,binary=True)
vi_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_file_vi,binary=True)
b = list(en_model.vocab)
bw = b[17]
bw

def remove

teacher_forcing_ratio = 0.5
def check_end(lst,batch):
  sum = 0 
  for i in range(batch):
    sum += int(lst[i])
  if sum == batch:
    return True
  else:
    return False
'''
  the input tensor and target tensor should be a batch of sentences
    shape of target and input are (B,T)

'''
def train(input_tensor, target_tensor, input_forest ,encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length,batch_size):
    # encoder_hidden = encoder.initHidden()

    encoder_optimizer.zero_grad()
    decoder_optimizer.zero_grad()

    target_length = 700
    loss = 0
    
    encoder_seq_output,encoder_tree_output,encoder_seq_hc,encoder_tree_hc = encoder(input_tensor,input_forest)

    
    word_input = []
    for i in range(batch_size):
      word_input.append(en_model.vocab['<start>'].index)
    decoder_input = torch.tensor(word_input, device=device)
    decoder_hidden = decoder.get_first_hidden(encoder_tree_hc[0],encoder_seq_hc[0],encoder_tree_hc[1],encoder_seq_hc[1])
    # print('first hidden shape',decoder_hidden.shape)
    # print('enc_output shape',encoder_seq_output.shape)
    # use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False
    use_teacher_forcing = True
    
    if use_teacher_forcing:
        # Teacher forcing: Feed the target as the next input
        # for bi in range(batch_size)
        for di in range(target_length):
            decoder_output, decoder_hidden, decoder_attention,decoder_tree_attention = decoder(
                decoder_input, decoder_hidden, encoder_seq_output.transpose(0,1),encoder_tree_output.transpose(0,1))
          
            loss += criterion(decoder_output, target_tensor[:,di])
      
            if check_end(decoder_input,batch_size):
              # print(decoder_input)
              break
            decoder_input = target_tensor[:,di]  # Teacher forcing
            
    else:
        # Without teacher forcing: use its own predictions as the next input
        for di in range(target_length):
            decoder_output, decoder_hidden, decoder_attention,decoder_tree_attention = decoder(
                decoder_input, decoder_hidden, encoder_seq_output.transpose(0,1),encoder_tree_output.transpose(0,1))
            '''
              decoder is in shape (B,H)
              mean first word of each sentence.
            '''
            loss += criterion(decoder_output, target_tensor[:,di])
            decoder_input = torch.Tensor( target_tensor[:,di])
            # topv, topi = decoder_output.topk(1)

            # decoder_input = topi.squeeze().detach()  # detach from history as input
            # if decoder_input.item() == EOS_token:
            #     break

    loss.backward()
    encoder_optimizer.step()
    decoder_optimizer.step()

    return loss.item() / target_length

'''
  split dataset into batch for training
  input_sentence is all sentence in the dataset
  input_forest is all trees that is parsed from sentences inside of the dataset
  target_sentence is all sentence that is translated from the other side
'''
def trainIters(encoder, decoder, input_sentence,input_tokenlist,target_sentence,batch_size,input_model,target_model, MAX_LENGTH,save_path,epoch,last_iter,encoder_optimizer,decoder_optimizer,print_every=400, plot_every=400):
    start = time.time()
    plot_losses = []
    print_loss_total = 0  # Reset every print_every
    plot_loss_total = 0  # Reset every plot_every

    criterion = nn.CrossEntropyLoss()
    # criterion = nn.MSELoss()

    total_exp = len(input_sentence)
    n_iters = int(total_exp/batch_size)
    checkpoint = last_iter * batch_size

    for iter in range(last_iter+1, n_iters + 1):
        # print(iter)
        input_batch = get_k_elements(source_list=input_sentence,batch_size=batch_size,start_point=checkpoint)
        forest_batch = get_k_elements(source_list=input_tokenlist,batch_size=batch_size,start_point=checkpoint)
        target_batch = get_k_elements(source_list=target_sentence,batch_size=batch_size,start_point=checkpoint)
        checkpoint += batch_size
        input_tensor,in_lengths = tensorFromSentence(model=input_model,sentences=input_batch,MAX_SEQUENCE_LENGTH=MAX_LENGTH)
        target_tensor,tar_lengths = tensorFromSentence(model=target_model,sentences=target_batch,MAX_SEQUENCE_LENGTH=MAX_LENGTH)
        input_forest = create_forest(forest_batch,input_model)
        loss = train(input_tensor, target_tensor,input_forest ,encoder,
                     decoder, encoder_optimizer, decoder_optimizer, criterion,MAX_LENGTH,batch_size)
        print_loss_total += loss
        plot_loss_total += loss

        if iter % print_every == 0:
            print_loss_avg = print_loss_total / print_every
            print_loss_total = 0
            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),
                                         iter, iter / n_iters * 100, print_loss_avg))

        if iter % plot_every == 0:
            plot_loss_avg = plot_loss_total / plot_every
            plot_losses.append(plot_loss_avg)
            plot_loss_total = 0
        if iter>0 and iter % 5000 == 0:
          enc_path = '{}/checkpoint.pt'.format(save_path)
          torch.save({
            'epoch':epoch,
            'iter': iter,
            'enc_state_dict': enc.state_dict(),
            'dec_state_dict': dec.state_dict(),
            'encoder_optimizer': encoder_optimizer.state_dict(),
            'decoder_optimizer': decoder_optimizer.state_dict(),
            'loss': loss,
            }, enc_path)
    # showPlot(plot_losses)
    return print_loss_total

def trainEpoch(enc,dec,input_data_path,target_data_path,input_forest_path,num_epoch,last_epoch,last_iter,save_path,learning_rate=0.01):
  import os
  encoder_optimizer = optim.SGD(enc.parameters(), lr=learning_rate)
  decoder_optimizer = optim.SGD(dec.parameters(), lr=learning_rate)
  for epoch in range(last_epoch,num_epoch):
    '''
      load data from file each time begin a new epoch
    '''
    epoch_path = '{}/checkpoint.pt'.format(save_path)
    # if os.path.exists(epoch_dir)== False:
    #   os.mkdir(epoch_dir)
    raw_input_text = open(input_data_path, 'rb').read().decode(encoding='utf-8')
    raw_target_text = open(target_data_path, 'rb').read().decode(encoding='utf-8')

    input_sentences = []
    target_sentences = []

    input_sentences.extend(raw_input_text.split('\n'))
    target_sentences.extend(raw_target_text.split('\n'))

    input_sent = preprocess_batch(input_sentences[:75000])
    target_sent = preprocessing_without_start(target_sentences[:75000])
    lst = load_token_list_from_file(input_forest_path)

    batch_size = 1
    loss = trainIters(enc, dec,input_sent,lst[:75000],target_sent, batch_size,vi_model,en_model,max_length,save_path,epoch,last_iter,encoder_optimizer,decoder_optimizer)
    print('finish epoch {} - loss {}'.format(epoch+1,loss))
    # spath = '{}/epoch_{}.pt'.format(epoch_dir,epoch)
    torch.save({
            'epoch': epoch,
            'iter':0,
            'enc_state_dict': enc.state_dict(),
            'dec_state_dict': dec.state_dict(),
            'encoder_optimizer': encoder_optimizer.state_dict(),
            'decoder_optimizer': decoder_optimizer.state_dict(),
            'loss': loss,
            }, epoch_path)
    last_iter = 0

# path = '../models/NMTmodels/training/checkpoint.pt'
# checkpoint = torch.load(path)
# input_size = 100
# hidden_size = 100
# p_dropout = 0.01
# max_length = 870
# enc = Tree2SeqEncoder(input_size,hidden_size,max_length,p_dropout,path_to_file_vi).to(device)
# dec = Decoder(input_size,hidden_size,max_length,path_to_file_en,hidden_size,len(en_model.vocab)).to(device)
# enc.load_state_dict(checkpoint['enc_state_dict'])
# dec.load_state_dict(checkpoint['dec_state_dict'])
# last_epoch = checkpoint['epoch']
# last_iter = checkpoint['iter']
# if iter == 0:
#   last_epoch = last_epoch + 1
# input_data_path = '../DataForNMT/2013/train-en-vi/train.vi'
# target_data_path = '../DataForNMT/2013/train-en-vi/train.en'
# input_forest_path = '../DataForNMT/2013/train_phonlp_token_list.txt'
# epoch = 17

# save_path = '../models/NMTmodels/training'
# # trainEpoch(enc,dec,input_data_path,target_data_path,input_forest_path,epoch,last_epoch,last_iter,save_path)

enc = Tree2SeqEncoder(input_size,hidden_size,max_length,p_dropout,path_to_file_vi).to(device)
dec = Decoder(input_size,hidden_size,max_length,path_to_file_en,hidden_size,len(en_model.vocab)).to(device)
# target_data_path = '../DataForNMT/2013/dev-2012-en-vi/tst2012.en'
# input_data_path = '../DataForNMT/2013/dev-2012-en-vi/tst2012.vi'
# input_forest_path = '../DataForNMT/2013/dev_phonlp_token_list.txt'
input_data_path = '../DataForNMT/2013/train-en-vi/train.vi'
target_data_path = '../DataForNMT/2013/train-en-vi/train.en'
input_forest_path = '../DataForNMT/2013/train_phonlp_token_list.txt'
epoch = 15
save_path = '../models/NMTmodels/training/200'
trainEpoch(enc,dec,input_data_path,target_data_path,input_forest_path,epoch,0,0,save_path)

from torchtext.data.metrics import bleu_score
'''
  sentence is a single Vietnamese sentence
'''
def get_words_from_index(listword,model):
  listvocab = list(model.vocab)
  result = []
  # print(len(listword))
  for word in listword:
    result.append(listvocab[word])
  # print(len(result))
  return result
def pre_translate(input_tensor,input_forest,encoder,decoder):
  encoder_seq_output,encoder_tree_output,encoder_seq_hc,encoder_tree_hc = encoder(input_tensor.to(device),input_forest)
  word_input = [en_model.vocab['<start>'].index]
  decoder_input = torch.Tensor(word_input).to(torch.int64).to(device)
  # print('first_input ',decoder_input)
  decoder_hidden = decoder.get_first_hidden(encoder_tree_hc[0],encoder_seq_hc[0],encoder_tree_hc[1],encoder_seq_hc[1])
  output = []
  while decoder_input.item()!=en_model.vocab['<end>'].index:
      decoder_output, decoder_hidden, decoder_attention,decoder_tree_attention = decoder(
          decoder_input, decoder_hidden, encoder_seq_output.transpose(0,1),encoder_tree_output.transpose(0,1))
      '''
        decoder is in shape (B,H)
        mean first word of each sentence.
      '''
      # print('a')
      topv, topi = decoder_output.topk(1)
      # print(decoder_output.topk(2))
      decoder_input = topi.squeeze(0).detach()  # detach from history as input
      # print('\n last input ',decoder_input)
      output.append(decoder_input[0].item())
  # print(len(output))
  output = get_words_from_index(output,en_model)
  return output
def translate(sentence,encoder,decoder):
  sentence = preprocessing(sentence)
  input_tensor,leng = tensorFromSentence(vi_model,[sentence],870)
  tokenlist = parsing_model.annotate(output_type='conll',text=sentence)
  input_forest = create_forest([tokenlist],vi_model)
  output = pre_translate(input_tensor,input_forest,encoder,decoder)
  return output
'''
  input_test is list of sentence in real sentence
  input_forest is list of parsed tree 
'''
def evaluation(enc,dec,input_test,forest,target_test):
  limit = len(input_test)
  results = []
  for i in range(limit):
    result = pre_translate(input_test[i].unsqueeze(0),[forest[i]],enc,dec)
    results.append(result)
  bleuscore = bleu_score(results,target_test)
  return bleuscore

a = translate('Tôi đã rất tự hào về đất nước tôi .',enc,dec)
a

test_tensor,lengs = tensorFromSentence(vi_model,test_vi,870)
lst = load_token_list_from_file(dev_file_path)
forest = create_forest(lst,vi_model)

bleu = evaluation(enc,dec,test_tensor,forest,test_en)
bleu

print(bleu)